{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Objectives\n",
    "\n",
    "Today we'll learn to things:  \n",
    "1. How to turn the entire internet into a data source  \n",
    "2. How to do that amazingly fast using threading\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "![webscraping](images/webscrape.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* Learning the basics of webscraping\n",
    " - HTTP vs HTML vs CSS\n",
    " - Requests\n",
    " - Session-based scraping\n",
    " - Crawling\n",
    " - Best practices\n",
    "* Unlearning the basics: there's a lot more depth\n",
    " - Common issues\n",
    " - Tor and Selenium\n",
    "* An intro to threading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Learning the basics of webscraping\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### HTTP vs HTML vs CSS\n",
    "\n",
    "* What are the difference between these terms?\n",
    "* CSS tags are what allow us to access the information we need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### The requests library\n",
    "\n",
    "* If you can see it, you can scrape it\n",
    "* A simple, powerful library\n",
    "* Also consider `urllib` and `urllib2`\n",
    "* Along with a parsing library like `bs4` (aka BeautifulSoup), this the defacto webscraping suite in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "url = 'http://www.galvanize.com'\n",
    "r = requests.get(url)\n",
    "r.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(r.text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html>\\n<html lang=\"en\">\\n\\t<head>\\n\\t\\t<script src=\"//cdn.optimizely.com/js/2974420093.js\"></script>\\n\\t\\t<meta charset=\"utf-8\">\\n    \\t<meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\\n\\t    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no\">\\n\\n\\t    <title>Galvanize | Learn Code, Analytics, Data Science | Startup Space</title>\\n\\t\\t<script type=\"text/javascript\">\\n\\t\\t\\tif (top != self) {\\n\\t\\t\\t\\tdocument.getElementsByTagName(\"HTML\")[0].style.display = \"none\";\\n\\t\\t\\t\\ttop.location=self.location;\\n\\t\\t\\t}\\n\\t\\t</script>\\n\\t\\t<link rel=\"icon\" type=\"image/png\" href=\"http://www.galvanize.com/wp-content/themes/galvanize/favicon.ico\">\\n\\t\\t<link rel=\"stylesheet\" type=\"text/css\" href=\"http://www.galvanize.com/wp-content/themes/galvanize/css/bootstrap.min.css\">\\n\\t\\t<link rel=\"stylesheet\" type=\"text/css\" href=\"http://www.galvanize.com/wp-content/themes/galvanize/style.css\" />\\n\\t\\t<link href=\"//maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css\" rel=\"st'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.text[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Session-based Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Check out http://galvanizesf.roomzilla.net\n",
    "# This site uses HTTP Basic Auth, one of the forms of authentication possible with this library\n",
    "z = requests.get('http://galvanizesf.roomzilla.net', auth=('', 'gVIP543'))\n",
    "# HTML(z.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "![formdata](images/chrome-view-post-data.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Courtesy of https://wpscholar.com/blog/view-form-data-in-chrome/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "z = requests.get('https://accounts.craigslist.org/login/home')\n",
    "# HTML(z.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pwd = 'pass_for_demo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = requests.Session()\n",
    "form_data = {'step':'confirmation',\n",
    "         'p': 0,\n",
    "         'rt': '',\n",
    "         'rp': '',\n",
    "         'inputEmailHandle':'conor.murphy@galvanize.com',\n",
    "         'inputPassword':pwd}\n",
    "headers = {\"Host\": \"accounts.craigslist.org\",\n",
    "           \"Origin\": \"https://accounts.craigslist.org\",\n",
    "           \"Referer\": \"https://accounts.craigslist.org/login\",\n",
    "           \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36\"}\n",
    "s.headers.update(headers)\n",
    "z = s.post('https://accounts.craigslist.org/login', data=form_data)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# HTML(z.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Crawling\n",
    "\n",
    "* A crawler sees two types of webpages\n",
    " - **seeds**: the urls the crawler begins with\n",
    " - **the crawl frontier**: the urls a crawler discovers on the sites it visits\n",
    "* You can build a simple crawler using the `requests` library and a parser.  For more advanced crawling, you'll have to deal with issues such as:\n",
    " - selection policies\n",
    " - politeness policies (to keep from overloading sites)\n",
    " - revisitation\n",
    " - parallelizing the work of different crawlers\n",
    "* Try using Scrapy for crawling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Best Practices\n",
    "\n",
    "* Always save all raw data\n",
    "* Follow this workflow:\n",
    " - Scrape\n",
    " - Store (unstructured, often with MongoDB)\n",
    " - Parse\n",
    " - Store (structured)\n",
    " - Analyze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Unlearning the basics: there's a lot more depth\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Common pitfalls:\n",
    "\n",
    "* rate limiting\n",
    "* blocking of certain ISP's (especially from AWS)\n",
    "* A/B testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* Tor and Selenium are two tools to allow you to work around some of these limitations\n",
    "* In essence, Tor disguises the originator of a message by daisy-chaining it across many users\n",
    "* Selenium automates web browsing, making you appear like normal user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## An intro to threading\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* Threads can be thought of multiple programs running simultaneously in the same process\n",
    "* Threads share the same scope/process\n",
    "* Threading is particularly helpful with I/O bound problems, like making GET requests to websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123145510092800"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread-3: Mon Apr  3 13:10:29 2017\n",
      "Thread-1: Mon Apr  3 13:10:30 2017\n",
      "Thread-3: Mon Apr  3 13:10:30 2017\n",
      "Thread-3: Mon Apr  3 13:10:31 2017\n",
      "Thread-2: Mon Apr  3 13:10:32 2017\n",
      "Thread-1: Mon Apr  3 13:10:32 2017\n",
      "Thread-3: Mon Apr  3 13:10:32 2017\n",
      "Thread-4: Mon Apr  3 13:10:33 2017\n",
      "Thread-3: Mon Apr  3 13:10:33 2017\n",
      "Thread-1: Mon Apr  3 13:10:34 2017\n",
      "Thread-2: Mon Apr  3 13:10:36 2017\n",
      "Thread-1: Mon Apr  3 13:10:36 2017\n",
      "Thread-4: Mon Apr  3 13:10:38 2017\n",
      "Thread-1: Mon Apr  3 13:10:38 2017\n",
      "Thread-2: Mon Apr  3 13:10:40 2017\n",
      "Thread-4: Mon Apr  3 13:10:43 2017\n",
      "Thread-2: Mon Apr  3 13:10:44 2017\n",
      "Thread-4: Mon Apr  3 13:10:48 2017\n",
      "Thread-2: Mon Apr  3 13:10:48 2017\n",
      "Thread-4: Mon Apr  3 13:10:53 2017\n"
     ]
    }
   ],
   "source": [
    "import _thread # this is the deprecated module for demonstration purposes.  Also see `threading`\n",
    "import time\n",
    "\n",
    "def print_time(threadName, delay):\n",
    "    '''\n",
    "    INPUT: name of thread as a string, delay time in seconds\n",
    "    OUTPUT: None, prints time 5 times\n",
    "    '''\n",
    "    count = 0\n",
    "    while count < 5:\n",
    "        time.sleep(delay)\n",
    "        count += 1\n",
    "        print(\"{}: {}\".format(threadName, time.ctime(time.time())))\n",
    "\n",
    "_thread.start_new_thread( print_time, (\"Thread-1\", 2, ) )\n",
    "_thread.start_new_thread( print_time, (\"Thread-2\", 4, ) )\n",
    "_thread.start_new_thread( print_time, (\"Thread-3\", 1, ) )\n",
    "_thread.start_new_thread( print_time, (\"Thread-4\", 5, ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Lab Overview\n",
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import queue\n",
    "from threading import Thread\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# specify sitemap to get all site links\n",
    "url_list = ['http://www.nytimes.com'] ## USE YOUR URLS HERE\n",
    "\n",
    "# create the queue instance and add urls to the queue\n",
    "q = queue.LifoQueue()\n",
    "[q.put(url) for url in url_list]\n",
    "\n",
    "# define how the URL transformations\n",
    "def grab_data_from_queue():\n",
    "    while not q.empty(): # check that the queue isn't empty\n",
    "        url = q.get() # get the item from the queue\n",
    "        r  = requests.get(url) # request the url\n",
    "\n",
    "        ## ADD YOUR CODE HERE\n",
    "\n",
    "        q.task_done() # specify that you are done with the item\n",
    "\n",
    "# create and start threads\n",
    "for i in range(12): # aka the number of threads\n",
    "    t1 = Thread(target = grab_data_from_queue) # target is the above function\n",
    "    t1.start() # start the thread\n",
    "\n",
    "q.join()\n",
    "\n",
    "print('This code took {} seconds'.format(time.time()-start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
