{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$.getScript('http://asimjalis.github.io/ipyn-ext/js/ipyn-present.js')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "$.getScript('http://asimjalis.github.io/ipyn-ext/js/ipyn-present.js')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 class=\"tocheading\">Lambda Architecture, Part 2</h1>\n",
    "<div id=\"toc\"></div>\n",
    "\n",
    "<i>N.B. blockquotes (and nearly all images) in this notebook are excerpts from [Big Data](https://www.manning.com/books/big-data) by Nathan Marz.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serving Layer\n",
    "===============================\n",
    "\n",
    "By the end of this lesson, you should be able to:\n",
    "\n",
    "* Tailor batch views to the queries they serve\n",
    "* Provide a new answer to the data-normalization versus denormalization debate\n",
    "* Discuss the advantages of batch-writable, random-read, and no random-write databases\n",
    "* Contrast a Lambda Architecture solution with a fully incremental solution\n",
    "\n",
    "Computing on the batch layer\n",
    "---------------------------------------------------------------------\n",
    "**The serving layer provides low-latency access to the results of calculations performed on the master dataset.**  \n",
    "![Lambda Architecture diagram](http://fr.talend.com/sites/default/files/hadoop_summit_2015_takeaway_the_lambda_architecture-picture_1.png)\n",
    "\n",
    "> While investigating the serving layer, you’ll learn the following:\n",
    ">\n",
    "* Indexing strategies to minimize latency, resource usage, and variance\n",
    "* The requirements for the serving layer in the Lambda Architecture\n",
    "* How the serving layer solves the long-debated normalization versus denormalization problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance metrics for the serving layer\n",
    "\n",
    "* _latency_ - the time required to answer a single query\n",
    "* _throughput_ - the number of queries that can be served within a given period of time\n",
    "\n",
    "### Scatter/Gather\n",
    "\n",
    "> Suppose a query requires fetching data from three servers...\n",
    ">\n",
    "![Figure 10.3](images/10fig03_alt.jpg)\n",
    "**When distributing a task over multiple servers, the overall latency is determined by the slowest server response time.**\n",
    "\n",
    "> In general, the more servers a query touches, the higher the overall latency of the query.  \n",
    ">\n",
    "![Figure 10.4](images/10fig04_alt.jpg)\n",
    "**If you increase the number of servers involved in a distributed task, you also increase the likelihood that at least one will respond slowly.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A different indexing strategy\n",
    "\n",
    "> Collocate the pageview information for a single URL on the same partition and store it sequentially. Fetching the pageviews will then only require a single seek and scan rather than numerous seeks.  \n",
    ">\n",
    "![Figure 10.5](images/10fig05_alt.jpg)\n",
    "**A sorted index promotes scans and limits disk seeks to improve both latency and throughput.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The serving layer solution to the normalization/denormalization problem\n",
    "### A normalized schema uses multiple independent datasets with little or no redundant data.\n",
    "\n",
    "| User ID | Name | Location ID |\n",
    "|:-:| ------ |:-:|\n",
    "| 1 | Sally  | 3 |\n",
    "| 2 | George | 1 |\n",
    "| 3 | Bob    | 3 |\n",
    "\n",
    "| Location ID | City | State | Population |\n",
    "|:------:| ---- | -- | ----:|\n",
    "| 1 | New York  | NY | 8.2M |\n",
    "| 2 | San Diego | CA | 1.3M |\n",
    "| 3 | Chicago   | IL | 2.7M |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denormalized tables store data redundantly to improve query performance.\n",
    "\n",
    "| User ID | Name | Location ID | City | State |\n",
    "|:-----:| ------ |:--:| ---- | -- |\n",
    "| 1 | Sally  | 3 | Chicago   | IL | \n",
    "| 2 | George | 1 | New York  | NY |\n",
    "| 3 | Bob    | 3 | Chicago   | IL | \n",
    "\n",
    "| Location ID | City | State | Population |\n",
    "|:------:| ---- | -- | ----:|\n",
    "| 1 | New York  | NY | 8.2M |\n",
    "| 2 | San Diego | CA | 1.3M |\n",
    "| 3 | Chicago   | IL | 2.7M |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The master dataset should be normalized to maintain consistency but the batch views may be denormalized for query efficiency. Since the batch views are _views_, this does not violate the principles of normaliziation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements for a serving layer database\n",
    "> \n",
    "* *Batch writable*—The batch views for a serving layer are produced from scratch. When a new version of a view becomes available, it must be possible to completely swap out the older version with the updated view.\n",
    "* *Scalable*—A serving layer database must be capable of handling views of arbitrary size. As with the distributed filesystems and batch computation framework previously discussed, this requires it to be distributed across multiple machines.\n",
    "* *Random reads*—A serving layer database must support random reads, with indexes providing direct access to small portions of the view. This requirement is necessary to have low latency on queries.\n",
    "* *Fault-tolerant*—Because a serving layer database is distributed, it must be tolerant of machine failures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Designing a serving layer for SuperWebAnalytics.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import simplejson as json\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import approxCountDistinct  # a.k.a. HyperLogLog\n",
    "\n",
    "try:  # only one SparkContext can exist at a time\n",
    "    if not sc:\n",
    "        sc = pyspark.SparkContext()\n",
    "except NameError:\n",
    "    sc = pyspark.SparkContext()\n",
    "\n",
    "sqlContext = pyspark.HiveContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preprocessed batch view pickled for your convenience:\n",
    "\n",
    "distinct_normalized_page_views = sc.pickleFile(\"data/distinct_normalized_page_views\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pageviews over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d': 86400, 'h': 3600, 'm': 2419200, 'w': 604800}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "granularity = {'h': 60 * 60}\n",
    "granularity['d'] = granularity['h'] * 24 # days in UTC (GMT) timezone\n",
    "granularity['w'] = granularity['d'] * 7\n",
    "granularity['m'] = granularity['w'] * 4  # 1 month = 28 days, not 1 calendar month\n",
    "granularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_granular(granual):\n",
    "    def func(datum): \n",
    "        url = datum['dataunit']['page_view']['page']['url']\n",
    "        true_as_of_secs = datum['pedigree']['true_as_of_secs']\n",
    "        return (url, granual, true_as_of_secs - true_as_of_secs % granularity[granual])\n",
    "    return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page_view_schema = StructType([\n",
    "    StructField('url', StringType() ,True),\n",
    "    StructField('granularity', StringType(), True),\n",
    "    StructField('ts', IntegerType(), True)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page_view_by_hour = sqlContext.createDataFrame(distinct_normalized_page_views.map(gen_granular('h')), \n",
    "                                               page_view_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hourly_page_views = page_view_by_hour.groupBy(['url', 'granularity', 'ts']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hourly_page_views.registerTempTable('hourly_page_views')\n",
    "sqlContext.cacheTable('hourly_page_views')\n",
    "\n",
    "# N.B. This won't work if you want your days to be in any timezone other than UTC\n",
    "daily_page_views = sqlContext.sql(\"\"\"SELECT url, 'd' AS granularity, ts - ts % {} AS ts, sum(count) AS count \n",
    "                                FROM hourly_page_views \n",
    "                                GROUP BY url, ts - ts % {}\"\"\".format(granularity['d'], granularity['d']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1\n",
    "\n",
    "How would you alter the above code to adjust for the Pacific timezone? (Hint: due to daylight savings time, you will probably want to use a timezone aware library like `pytz`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------+----------+------+\n",
      "|            url|granularity|        ts| count|\n",
      "+---------------+-----------+----------+------+\n",
      "|    mysite.com/|          h|1438912800|300054|\n",
      "|    mysite.com/|          h|1438624800|101212|\n",
      "|    mysite.com/|          d|1438905600|300054|\n",
      "|    mysite.com/|          d|1438560000|101212|\n",
      "|mysite.com/blog|          h|1438912800|899778|\n",
      "|mysite.com/blog|          h|1438624800|101732|\n",
      "|mysite.com/blog|          d|1438560000|101732|\n",
      "|mysite.com/blog|          d|1438905600|899778|\n",
      "+---------------+-----------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "page_view_union = hourly_page_views.unionAll(daily_page_views).orderBy('url')\n",
    "page_view_union.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page_view_union.write.parquet(\"data/page_views\", mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniques over time\n",
    "<blockquote><p><b><i>Index design for uniques over time. Although the index keys are a compound of URL and granularity, indexes are partitioned\n",
    "         between servers solely by the URL.\n",
    "      </i></b></p>\n",
    "      \n",
    "      <p class=\"center1\"><img src=\"images/10fig08_alt.jpg\" alt=\"\" class=\"calibre2\"/></p>\n",
    "      \n",
    "      \n",
    "      <p class=\"noind\"><a id=\"iddle1159\" class=\"calibre4\"></a><a id=\"iddle1327\" class=\"calibre4\"></a><a id=\"iddle1603\" class=\"calibre4\"></a><a id=\"iddle1609\" class=\"calibre4\"></a><a id=\"iddle1718\" class=\"calibre4\"></a>In this case, an index like that represented [above] seems optimal. It’s the same key-to-sorted-map index as was used for pageviews over time, but with two differences:\n",
    "      </p>\n",
    "      \n",
    "      <p class=\"calibre16\"></p>\n",
    "      <ul class=\"calibre17\">\n",
    "         \n",
    "         <li class=\"calibre18\">The key is a compound key of URL and granularity.\n",
    "            \n",
    "         </li>\n",
    "         \n",
    "         <li class=\"calibre18\">The indexes are partitioned solely by the URL, not by both the URL and granularity. To retrieve a range of values for a URL\n",
    "            and granularity, you’d use the URL to find the server containing the information you need, and then use both the URL and granularity\n",
    "            to look up the values you’re interested in. Partitioning by just the URL ensures that all buckets for a URL are collocated\n",
    "            on the same server and avoids any variance issues from having to interact with many servers for a single query.\n",
    "            \n",
    "         </li>\n",
    "         \n",
    "      </ul></blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def user_row(granual):\n",
    "    import simplejson as json\n",
    "    granularity = {'h': 60 * 60}\n",
    "    granularity['d'] = granularity['h'] * 24 # days in UTC (GMT) timezone\n",
    "    granularity['w'] = granularity['d'] * 7\n",
    "    granularity['m'] = granularity['w'] * 4  # 1 month = 28 days, not 1 calendar month\n",
    "    def func(datum):\n",
    "        url = datum['dataunit']['page_view']['page']['url']\n",
    "        true_as_of_secs = datum['pedigree']['true_as_of_secs']\n",
    "        person = json.dumps(datum['dataunit']['page_view']['person'])\n",
    "        return (url, granual, true_as_of_secs - true_as_of_secs % granularity[granual], person)\n",
    "    return func\n",
    "\n",
    "visit_schema = StructType([\n",
    "    StructField('url', StringType() ,True),\n",
    "    StructField('granularity', StringType(), True),\n",
    "    StructField('ts', IntegerType(), True),\n",
    "    StructField('person', StringType(), True)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(url=u'mysite.com/blog', granularity=u'h', ts=1438912800, person=u'{\"cookie\": \"PQRST\"}'),\n",
       " Row(url=u'mysite.com/blog', granularity=u'h', ts=1438912800, person=u'{\"user_id\": 5693}'),\n",
       " Row(url=u'mysite.com/blog', granularity=u'h', ts=1438912800, person=u'{\"user_id\": 6257}'),\n",
       " Row(url=u'mysite.com/', granularity=u'h', ts=1438912800, person=u'{\"user_id\": 765}'),\n",
       " Row(url=u'mysite.com/blog', granularity=u'h', ts=1438912800, person=u'{\"user_id\": 7132}')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_visits = sqlContext.createDataFrame(distinct_normalized_page_views.map(user_row('h')),\n",
    "                                           visit_schema)\n",
    "hourly_visits.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hourly_visits.write.parquet('data/hourly_visits/', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "visits_by_hour = hourly_visits.groupBy(['url', 'granularity', 'ts'])\\\n",
    "                              .agg(approxCountDistinct('person').alias('approx_uniques'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2\n",
    "\n",
    "Create view of visits by day. \n",
    "\n",
    "Bonus: Adjust for the Pacific timezone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3\n",
    "\n",
    "1. Merge results with those above and write the results to parquet files in `data/visits`.\n",
    "2. Group by `['url', 'granularity', 'ts']` and run `approxCountDistinct`. The results should look like:  \n",
    "\n",
    "```\n",
    "    +---------------+-----------+----------+--------------+\n",
    "    |            url|granularity|        ts|approx_uniques|\n",
    "    +---------------+-----------+----------+--------------+\n",
    "    |    mysite.com/|          d|1438560000|         10874|\n",
    "    |    mysite.com/|          d|1438905600|         10893|\n",
    "    |    mysite.com/|          h|1438624800|         10874|\n",
    "    |    mysite.com/|          h|1438912800|         10893|\n",
    "    |mysite.com/blog|          h|1438912800|         10893|\n",
    "    |mysite.com/blog|          h|1438624800|         10776|\n",
    "    |mysite.com/blog|          d|1438560000|         10776|\n",
    "    |mysite.com/blog|          d|1438905600|         10893|\n",
    "    +---------------+-----------+----------+--------------+\n",
    "```\n",
    "\n",
    "Bonus: Use this to query from August 3, 3am until August 6, 3am.\n",
    "\n",
    "Hint: ![Figure 8.3](images/08fig03_alt.jpg)  \n",
    "You may want to fill in more hours to make sure your code works correctly. These data are just a small sample to get you started and only include 2 hours, so be careful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# write code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User-identifier normalization\n",
    "\n",
    "> User IDs are marked as belonging to the same person via equiv edges. If you were to visualize these edges from a dataset, you’d see numerous independent subgraphs \n",
    ". . . \n",
    "> Each subgraph represents a unique user.\n",
    ">  \n",
    "![Figure 9.3](images/09fig03_alt.jpg)  \n",
    "\n",
    "Such graphs can be obtained using [GraphX](http://spark.apache.org/graphx/) (not yet included in PySpark)\n",
    "\n",
    "#### Handling equivs on the read-side workflow\n",
    "> \n",
    "> ![Figure 10.11](images/10fig11_alt.jpg)\n",
    "> \n",
    "1. First, retrieve every UserID set for every hour in the range, and merge them.\n",
    "2. Convert the set of UserIDs to a set of PersonIDs by using the UserID-to-PersonID index.\n",
    "3. Return the count of the PersonID set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speed Layer\n",
    "===============================\n",
    "\n",
    "By the end of this lesson, you should be able to:\n",
    "\n",
    "* Enqueue page-views in Kafka\n",
    "* Dedupe and normalize using Spark Streaming\n",
    "* Store Pageviews over time in HBase\n",
    "* Expire data in HBase as appropriate\n",
    "\n",
    "> This section covers:\n",
    ">  \n",
    "* The theoretical model of the speed layer\n",
    "* How the batch layer eases the responsibilities of the speed layer\n",
    "* Using random-write databases for realtime views\n",
    "* The CAP theorem and its implications\n",
    "* The challenges of incremental computation\n",
    "* Expiring data from the speed layer\n",
    "\n",
    "> **The speed layer allows the Lambda Architecture to serve low-latency queries over up-to-date data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing realtime views\n",
    "---------------------------------------------------------------------\n",
    "\n",
    "### Strategy: realtime view = function(recent data)\n",
    "\n",
    "![Figure 12.2](images/12fig02_alt.jpg)\n",
    "\n",
    "### Incremental strategy: realtime view = function(new data, previous realtime view)\n",
    "\n",
    "![Figure 12.3](images/12fig03_alt.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing realtime views\n",
    "---------------------------------------------------------------------\n",
    "> \n",
    "* *Random reads*—A realtime view should support fast random reads to answer queries quickly. This means the data it contains must be indexed.\n",
    "* *Random writes*—To support incremental algorithms, it must also be possible to modify a realtime view with low latency.\n",
    "* *Scalability*—As with the serving layer views, the realtime views should scale with the amount of data they store and the read/write rates required by the applica- tion. Typically this implies that realtime views can be distributed across many machines.\n",
    "* *Fault tolerance*—If a disk or a machine crashes, a realtime view should continue to function normally. Fault tolerance is accomplished by replicating data across machines so there are backups should a single machine fail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eventual accuracy\n",
    "\n",
    "> Because all data is eventually represented in the batch and serving layer views, any approximations you make in the speed layer are continually corrected.\n",
    "\n",
    "### Amount of state stored in the speed layer\n",
    "> \n",
    "* *Online compaction*—As a read/write database receives updates, parts of the disk index become unused, wasted space. Periodically the database must perform compaction to reclaim space. Compaction is a resource-intensive process and could potentially starve the machine of resources needed to rapidly serve queries. Improper management of compaction can cause a cascading failure of the entire cluster.\n",
    "* *Concurrency*—A read/write database can potentially receive many reads or writes for the same value at the same time. It therefore needs to coordinate these reads and writes to prevent returning stale or inconsistent values. Sharing mutable state across threads is a notoriously complex problem, and control strategies such as locking are notoriously bug-prone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Challenges of incremental computation\n",
    "---------------------------------------------------------------------\n",
    "\n",
    "### Validity of the CAP theorem\n",
    "\n",
    "![Figure 12.4](images/12fig04_alt.jpg)\n",
    "\n",
    "**Replicas can diverge if updates are allowed under partitions.**\n",
    "\n",
    "### The complex interaction between the CAP theorem and incremental algorithms\n",
    "\n",
    "**conflict-free replicated data types (*CRDT*s)**\n",
    "\n",
    "#### A G-Counter is a grow-only counter where a replica only increments its assigned counter. \n",
    "\n",
    "![Figure 12.5](images/12fig05_alt.jpg)\n",
    "\n",
    "_N.B._ G-Counter is implemented as an [`accumulator`](http://spark.apache.org/docs/latest/programming-guide.html#accumulators-a-nameaccumlinka) in Spark\n",
    "\n",
    "**The overall value of the accumulator is the sum of the replica counts.**\n",
    "\n",
    "#### Merging G-Counters\n",
    "\n",
    "![Figure 12.6](images/12fig06_alt.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asynchronous versus synchronous updates\n",
    "---------------------------------------------------------------------\n",
    "\n",
    "### A simple speed layer architecture using synchronous updates\n",
    "\n",
    "![Figure 12.7](images/12fig07.jpg)\n",
    "\n",
    "### Asynchronous updates provide higher throughput and readily handle variable loads.\n",
    "\n",
    "![Figure 12.8](images/12fig08_alt.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expiring realtime views\n",
    "---------------------------------------------------------------------\n",
    "\n",
    "***The state of the serving and speed layer views at the end of the first batch computation run:***\n",
    "\n",
    "![Figure 12.9](images/12fig09.jpg)\n",
    "\n",
    "***A portion of the realtime views can be expired after the second run completes:***\n",
    "\n",
    "![Figure 12.10](images/12fig10.jpg)\n",
    "\n",
    "***The serving and speed layer views immediately before the completion of the third batch computation run:***\n",
    "\n",
    "![Figure 12.11](images/12fig11_alt.jpg)\n",
    "\n",
    "***Alternating clearing between two different sets of realtime views guarantees one set always contains the appropriate data for the speed layer:***\n",
    "\n",
    "![Figure 12.12](images/12fig12_alt.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queueing and stream processing\n",
    "---------------------------------------------------------------------\n",
    "\n",
    "**To implement asynchronous processing without queues, a client submits an event without monitoring whether its processing is successful.**\n",
    "\n",
    "![Figure 14.1](images/14fig01.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queuing\n",
    "---------------------------------------------------------------------\n",
    "---------------------------------------------------------------------\n",
    "\n",
    "### Single-consumer queue servers\n",
    "\n",
    "![Figure 14.2](images/14fig02.jpg)\n",
    "\n",
    "**Multiple applications sharing a single queue consumer**\n",
    "\n",
    "---------------------------------------------------------------------\n",
    "\n",
    "### Multi-consumer queues\n",
    "\n",
    "![Figure 14.3](images/14fig03_alt.jpg)\n",
    "\n",
    "**With a multi-consumer queue, applications request specific items from the queue and are responsible for tracking the successful processing of each event.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stream processing\n",
    "---------------------------------------------------------------------\n",
    "\n",
    "![Figure 14.4](images/14fig04_alt.jpg)\n",
    "\n",
    "---------------------------------------------------------------------\n",
    "\n",
    "**Comparison of stream-processing paradigms**  \n",
    "(*i.e.* Storm vs. Spark Streaming)\n",
    "![Figure 14.5](images/14fig05.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Queues and workers\n",
    "\n",
    "---------------------------------------------------------------------\n",
    "\n",
    "#### A representative system using a queues-and-workers architecture. \n",
    "\n",
    "![Figure 14.6](images/14fig06_alt.jpg)\n",
    "\n",
    "**The queues in the diagram could potentially be distributed queues as well.**\n",
    "\n",
    "---------------------------------------------------------------------\n",
    "\n",
    "#### Computing pageviews over time with a queues-and-workers architecture\n",
    "\n",
    "![Figure 14.7](images/14fig07_alt.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Micro-batch stream processing\n",
    "===============================================================\n",
    "> This section covers:\n",
    ">  \n",
    "* Exactly-once processing semantics\n",
    "* Micro-batch processing and its trade-offs\n",
    "* Extending pipe diagrams for micro-batch stream processing\n",
    "\n",
    "Achieving exactly-once semantics\n",
    "---------------------------------------------------------------------\n",
    "\n",
    "### Strongly ordered processing\n",
    ">  \n",
    "* The stored ID is the same as the current tuple ID. In this case, you know that the count already reflects the current tuple, so you do nothing.\n",
    "* The stored ID is different from the current tuple ID. In this case, you know that the count doesn’t reflect the current tuple. So you increment the counter and update the stored ID. This works because tuples are processed in order, and the count and ID are updated atomically.\n",
    "\n",
    "### Micro-batch stream processing\n",
    "\n",
    "**Tuple stream divided into batches**\n",
    "\n",
    "![Figure 16.1](images/16fig01.jpg)\n",
    "\n",
    "### Micro-batch processing topologies\n",
    "\n",
    "#### Each batch includes tuples from all partitions of the incoming stream.\n",
    "\n",
    "![Figure 16.4](images/16fig04.jpg)\n",
    "\n",
    "**Word-count topology:**\n",
    "\n",
    "![Figure 16.5](images/16fig05.jpg)\n",
    "\n",
    "**Storing word counts with batch IDs:**\n",
    "\n",
    "![Figure 16.6](images/16fig06.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Core concepts of micro-batch stream processing\n",
    "---------------------------------------------------------------------\n",
    ">  \n",
    "* *Batch-local computation*—There’s computation that occurs solely within the batch, not dependent on any state being kept. This includes things like reparti- tioning the word stream by the word field and computing the count of all the tuples in a batch.\n",
    "* *Stateful computation*—Then there’s computation that keeps state across all batches, such as updating a global count, updating word counts, or storing a top-three list of most frequently used words. This is where you have to be really careful about how you do state updates so that processing is idempotent under failures and retries. The trick of storing the batch ID with the state is particu- larly useful here to add idempotence to non-idempotent operations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realtime views\n",
    "---------------------------------------------------------------------\n",
    "\n",
    "Three separate queries one might implement for a website:\n",
    "\n",
    ">  \n",
    "* Number of pageviews over a range of hours\n",
    "* Unique number of visitors over a range of hours\n",
    "* Bounce rate for a domain  \n",
    "    \n",
    "---------------------------------------------------------------------\n",
    "\n",
    "> Consider the following sequence of events:\n",
    ">  \n",
    "1. IP address `11.11.11.111` visits `foo.com/about` at 1:30 pm.\n",
    "2. User `sally` visits `foo.com/about` at 1:40 pm.\n",
    "3. An equiv edge between `11.11.11.111` and `sally` is discovered at 2:00 pm.\n",
    "\n",
    "### Topology structure\n",
    "\n",
    "1. Consume a stream of pageview events that contains a user identifier, a URL, and a timestamp.\n",
    "2. Normalize URLs.\n",
    "3. Update a database containing a nested map from URL to hour to a HyperLogLog (*i.e.* `approxCountDistinct`) set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining data systems\n",
    "\n",
    "$$\n",
    "\\text{query} = function(\\text{all data})\n",
    "$$  \n",
    "\n",
    "* *Latency*—The time it takes to run a query. May be milliseconds to hours.\n",
    "* *Timeliness*—How up-to-date the query results are. \n",
    "* *Accuracy*—In many cases, approximations may be necessary\n",
    "\n",
    "> ...mutability—and associated concepts like CRUD—are fundamentally not human-fault tolerant...  \n",
    "> ...solution is to make your core data *immutable*...  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch and serving layers\n",
    "\n",
    "** Basic birthday-inference algorithm **\n",
    "\n",
    "![Figure 18.1](images/18fig01_alt.jpg)\n",
    "\n",
    "### Partial Recomputation\n",
    ">  \n",
    "1. For the new batch of data, find all people who have a new age sample.\n",
    "2. Retrieve all age samples from the master dataset for all people in step 1.\n",
    "3. Recompute the birthdays for all people in step 1 using the age samples from step 2 and the age samples in the new batch.\n",
    "4. Merge the newly computed birthdays into the existing serving layer views.\n",
    "\n",
    "** Bloom join **\n",
    "\n",
    "![Figure 18.2](images/18fig02.jpg)\n",
    "\n",
    "### Measuring and optimizing batch layer resource usage\n",
    "> Consider these examples, which are based on real-world cases:\n",
    "* After doubling the cluster size, the latency of a batch layer went down from 30 hours to 6 hours, an 80% improvement.\n",
    "* An improper reconfiguration caused a Hadoop cluster to have 10% more task failure rates than before. This caused a batch workflow’s runtime to go from 8 hours to 72 hours, a 9x degradation in performance.\n",
    "\n",
    "\n",
    "* $T$—The runtime of the workflow in hours.\n",
    "* $O$—The overhead of the workflow in hours (_things like setting up processes, copying code, etc._)\n",
    "* $H$—The amount of data being processed (_it’s assumed that the rate of incoming data is fairly constant._)\n",
    "* $P$—The dynamic processing time. (_i.e. number of hours each unit of $H$ adds_)\n",
    "\n",
    "$$T = O + P \\times H $$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
